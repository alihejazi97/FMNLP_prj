{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7U6-5U8qGoV",
        "outputId": "3d0ad4b5-d306-4606-8e5e-a1895e74b3a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-31 17:28:10--  https://raw.githubusercontent.com/allenai/bi-att-flow/master/squad/evaluate-v1.1.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3419 (3.3K) [text/plain]\n",
            "Saving to: ‘evaluate_squad.py’\n",
            "\n",
            "evaluate_squad.py   100%[===================>]   3.34K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-01-31 17:28:10 (21.0 MB/s) - ‘evaluate_squad.py’ saved [3419/3419]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# !pip install openai\n",
        "!wget https://raw.githubusercontent.com/allenai/bi-att-flow/master/squad/evaluate-v1.1.py -O evaluate_squad.py\n",
        "# !pip install sentencepiece\n",
        "# !pip install peft\n",
        "# !pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import sys\n",
        "sys.path.append('/content/drive/')\n",
        "from evaluate_squad import evaluate\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXwoo76YqjMI",
        "outputId": "57821a98-265b-4d53-abed-ac8679b8b726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/xquad.zh.json', 'r', encoding='utf-8') as f:\n",
        "    dataset_file = json.load(f)\n",
        "with open('/content/drive/MyDrive/GPT_35_TURBO_normal/xquad.zh.json', 'r', encoding='utf-8') as f:\n",
        "    prediction_obj = json.load(f)\n",
        "\n",
        "dataset = dataset_file['data']\n",
        "predictions = {}\n",
        "for prediction in prediction_obj:\n",
        "    for key, value in prediction.items():\n",
        "        predictions[key] = value"
      ],
      "metadata": {
        "id": "KK0VRNZd0isa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(dataset, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzaS-yZe3Y1b",
        "outputId": "3089a1e6-cb03-47df-a3c3-5524f6a8a01d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exact_match': 34.621848739495796, 'f1': 36.80462441386812}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    }
  ]
}